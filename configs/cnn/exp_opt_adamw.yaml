train:
  optimizer: "adamw"
  lr: 0.001
  weight_decay: 0.0001

logging:
  run_name: "opt_adamw"
